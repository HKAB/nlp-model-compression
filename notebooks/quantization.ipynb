{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c8eba1-668b-4371-b22b-8b29b96108ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import AdamW\n",
    "from utils import EarlyStopping, TokenClassificationDataset\n",
    "import io\n",
    "from torch.utils.data import DataLoader\n",
    "import optparse\n",
    "import pickle\n",
    "from constants import *\n",
    "import os.path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c83f3748-bc4c-448d-946b-207f7099d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40efa2c3-d544-4b25-93df-42108d41d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_latency(model, inputs, num_samples=100, num_warmups=100):\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_warmups):\n",
    "            _ = model(torch.unsqueeze(inputs['ids'], 0), torch.unsqueeze(inputs['masks'], 0))\n",
    "#     torch.cuda.synchronize()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        stime = time.time()\n",
    "        for _ in range(num_samples):\n",
    "            _ = model(torch.unsqueeze(inputs['ids'], 0), torch.unsqueeze(inputs['masks'], 0))\n",
    "#             torch.cuda.synchronize()\n",
    "        etime = time.time()\n",
    "    elapsed_time = etime - stime\n",
    "    \n",
    "    return elapsed_time, elapsed_time/num_samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77fcd84-bd75-4d83-aae3-05fa937e56bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_VISIBLE_DEVICES\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a375bfd3-b130-4c53-af6e-9fcddba231e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_list = NER_TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2055ca6e-10a4-4e65-a86d-5389dbbd075a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df293cff-fd0c-4f76-957a-fbbf07130853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaForTokenClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(target_list)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"vinai/phobert-base\", \n",
    "                                                        num_labels=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf8f9f6c-2758-4ca8-b5fa-25453e376a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf378f1e-9310-4992-841e-14665f75f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quantized_model.state_dict(), RESULT_PATH + \"/quantized_NER_Pretrained_phoBERT.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5adee4b7-e22b-4068-a834-18ecc084b4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 512)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(RESULT_PATH + \"/quantized_NER_Pretrained_phoBERT.pt\")//(2 ** 20), \\\n",
    "os.path.getsize(RESULT_PATH + \"/NER_Pretrained_phoBERT.pt\")//(2 ** 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57de657b-4cf7-47f2-afab-2b06a22915f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NER data sucessfully!\n"
     ]
    }
   ],
   "source": [
    "target_list = NER_TARGET\n",
    "with io.open(NER_PATH_TEST, encoding='utf-8') as f:\n",
    "    test_task = f.read()\n",
    "test_task = test_task.split('\\n\\n')\n",
    "print('Load NER data sucessfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a6814a-889a-4e97-af0f-a2c48e7a6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer, using cpu\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=True)\n",
    "print(f'Loaded tokenizer, using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b8dad70-db50-4b85-bf4c-b8100214b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task = test_task[:1]    \n",
    "test_dataset = TokenClassificationDataset(test_task, target_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0596a897-f2db-4904-a0dc-419714c74bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  1108,  1612,  1896,   802,  9443,   238,    60,    48,    82,\n",
       "            78,  7164,   126, 13098,    72,   150,   355, 29618,    26,   337,\n",
       "            44,    13,   283,   523,    28,   224,   366,     7,   327,     5,\n",
       "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(test_dataset[0]['ids'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b12197d6-6080-48bd-abbf-1f67f7cad7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46.35512590408325, 0.4635512590408325)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_latency(model, test_dataset[0], num_samples=100, num_warmups=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f0f678e-59f4-4fab-83b3-7cfc1d925bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.60396456718445, 0.3160396456718445)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_latency(quantized_model, test_dataset[0], num_samples=100, num_warmups=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
