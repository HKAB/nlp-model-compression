{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca40d2b-9a54-4e04-9f6a-84bd6279bd95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PretrainedConfig,\n",
    "    SchedulerType,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "# My custom model\n",
    "from models import BertForSequenceClassification\n",
    "from models import DeeBertForSequenceClassification\n",
    "from models import BertConfig\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bbcb6-afa9-47cd-b521-12a65318cad0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test my BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f4ceb-a543-432e-aa39-38652e90d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# change model pretrained path here\n",
    "config = BertConfig(exit_port_threshold=0.1, entropy_threshold=0.2)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce5303-9cc9-46dd-8b2e-07142aab3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0) # batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c5c87-87e1-4272-9d26-4e9e12564a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first phrase\n",
    "outputs = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2196eb-252b-479d-a627-a2e0b8a00dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second phrase\n",
    "outputs = model.exit_forward(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595af8d4-44a3-47c6-8f73-a3fde6938ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.entropy_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae60a1d-0451-45bd-82e9-b3cc3e732daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2306971-b0fe-41ba-b1e4-c63bf05e5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world Yo yo\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed676c69-743b-4c07-887d-b2a59f946ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.exit_inference_forward(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca89e24-f9ed-4017-a138-ff680d36d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stop_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947ab01-c354-4424-b21b-f0db5deb3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb56250-2827-4aa4-b205-a3dca3cdbc5f",
   "metadata": {},
   "source": [
    "# Test DeeBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5e2de-256f-48f1-b975-7e49c8d6b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# change model pretrained path here\n",
    "config = BertConfig(entropy_threshold=0.5)\n",
    "model = DeeBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9333b48-cf37-450d-9219-effdd11ae875",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world haha, Excuse me\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedee9bf-73db-4db3-940d-17d25dd6f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first phrase\n",
    "outputs = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe2e60-8452-4ec9-808d-6d54b5333199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second phrase\n",
    "outputs = model.exit_inference_forward(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeed24f-a8fd-4bb0-9a58-30733cb07c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stop_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451464e9-bff7-45cc-a694-dba8023d857c",
   "metadata": {},
   "source": [
    "# Test result of new idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52205fb-33c7-45ed-a6ee-909b11ce5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.cat((torch.rand((32, 1)), torch.randint(0, 2, (32, 1))), dim = 1) for _ in range(0, 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a830d-4bc6-43cb-b1cd-b066c894ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = a[0][:, 0].unsqueeze(1)\n",
    "y = a[0][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea33b5b-e6b8-49c6-9519-317b688dc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.hstack((X, torch.zeros_like(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639cc04-eafb-4e0a-8902-8615538767b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a128ed1-d674-43ee-87d2-3b17c9714060",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21bced3-f8cd-4c1e-9e41-c4d340897091",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = clf.coef_[0]\n",
    "x_0 = -clf.intercept_[0]/w[0]\n",
    "margin = w[0]\n",
    "w, x_0, margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd09457-ecf0-4a92-9dbb-317525bbf5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x_min, x_max = torch.floor(X.min()), torch.ceil(X.max())\n",
    "y_min, y_max = -3, 3\n",
    "yy = torch.linspace(y_min, y_max, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f39642-9f8f-45c4-bdd0-53224ed3e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[torch.where(y > 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e11b7-799a-4104-be98-09492a060cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[torch.where(y > 0)[0]], torch.zeros_like(X[torch.where(y > 0)[0]]), c=\"red\")\n",
    "plt.scatter(X[torch.where(y < 1)[0]], torch.zeros_like(X[torch.where(y < 1)[0]]), c=\"blue\")\n",
    "plt.plot(x_0*torch.ones_like(yy), yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b507d34-bae9-4510-843c-0af6834cb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_point = []\n",
    "fig, axs = plt.subplots(3, 4, figsize=(16, 9))\n",
    "for i in range(0, 12):\n",
    "    X = a[i][:, 0].unsqueeze(1)\n",
    "    y = a[i][:, 1]\n",
    "    X = torch.hstack((X, torch.zeros_like(X)))\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(X, y)\n",
    "    optimal_point.append(-clf.intercept_[0]/w[0])\n",
    "    \n",
    "    x_min, x_max = torch.floor(X.min()), torch.ceil(X.max())\n",
    "    y_min, y_max = -3, 3\n",
    "    yy = torch.linspace(y_min, y_max, 3)\n",
    "    \n",
    "    axs[int(i/4), i%4].scatter(X[torch.where(y > 0)[0]], torch.zeros_like(X[torch.where(y > 0)[0]]), c=\"red\")\n",
    "    axs[int(i/4), i%4].scatter(X[torch.where(y < 1)[0]], torch.zeros_like(X[torch.where(y < 1)[0]]), c=\"blue\")\n",
    "    axs[int(i/4), i%4].plot(x_0*torch.ones_like(yy), yy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
