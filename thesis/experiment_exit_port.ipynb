{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca40d2b-9a54-4e04-9f6a-84bd6279bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PretrainedConfig,\n",
    "    SchedulerType,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "# My custom model\n",
    "from models import BertForSequenceClassification\n",
    "from models import BertConfig\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5f4ceb-a543-432e-aa39-38652e90d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifiers.5.bias', 'classifiers.1.weight', 'exit_port.11.weight', 'exit_port.6.bias', 'exit_port.4.weight', 'exit_port.1.weight', 'exit_port.9.weight', 'classifiers.7.bias', 'classifiers.10.bias', 'exit_port.8.bias', 'classifiers.6.bias', 'exit_port.7.weight', 'exit_port.2.weight', 'classifiers.4.bias', 'exit_port.7.bias', 'exit_port.11.bias', 'classifiers.8.weight', 'classifiers.10.weight', 'classifiers.4.weight', 'classifiers.2.weight', 'classifiers.3.bias', 'exit_port.9.bias', 'classifiers.3.weight', 'exit_port.2.bias', 'classifiers.9.bias', 'classifiers.8.bias', 'classifiers.5.weight', 'classifiers.2.bias', 'exit_port.3.bias', 'exit_port.4.bias', 'exit_port.8.weight', 'classifiers.1.bias', 'exit_port.10.bias', 'classifiers.7.weight', 'exit_port.10.weight', 'classifiers.6.weight', 'classifiers.0.weight', 'classifiers.11.weight', 'exit_port.5.bias', 'exit_port.6.weight', 'classifiers.11.bias', 'exit_port.0.weight', 'exit_port.1.bias', 'classifiers.0.bias', 'exit_port.3.weight', 'exit_port.0.bias', 'classifiers.9.weight', 'exit_port.5.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# change model pretrained path here\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ce5303-9cc9-46dd-8b2e-07142aab3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world\", \"Yo yo\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([1, 0]).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a56c5c87-87e1-4272-9d26-4e9e12564a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first phrase\n",
    "outputs = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb341385-6170-492d-a437-66c3e025e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world\", \"Yo yo\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([1, 0]).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2196eb-252b-479d-a627-a2e0b8a00dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second phrase\n",
    "outputs = model.exit_forward(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae60a1d-0451-45bd-82e9-b3cc3e732daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed676c69-743b-4c07-887d-b2a59f946ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.exit_inference(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb40b97-5105-4e86-bb13-11f365ed64b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.2424, -0.0581],\n",
       "        [ 0.3143,  0.1327]], grad_fn=<AddmmBackward>), hidden_states=(tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "           3.8253e-02,  1.6400e-01],\n",
       "         [ 3.7386e-01, -1.5575e-02, -2.4561e-01,  ..., -3.1657e-02,\n",
       "           5.5144e-01, -5.2406e-01],\n",
       "         [ 4.6709e-04,  1.6225e-01, -6.4443e-02,  ...,  4.9443e-01,\n",
       "           6.9413e-01,  3.6286e-01],\n",
       "         ...,\n",
       "         [ 2.6543e-02, -1.7981e-01,  4.8942e-01,  ..., -5.3213e-01,\n",
       "          -2.4651e-01,  4.6587e-01],\n",
       "         [-1.1945e-01, -2.3242e-01,  2.4277e-01,  ..., -4.7397e-01,\n",
       "          -1.3933e-01,  3.1804e-01],\n",
       "         [ 1.1076e-01, -7.5039e-02,  3.2258e-01,  ..., -7.3081e-02,\n",
       "          -5.1369e-01,  2.2897e-01]],\n",
       "\n",
       "        [[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "           3.8253e-02,  1.6400e-01],\n",
       "         [ 5.7398e-02,  1.0238e+00, -1.4485e-01,  ...,  1.0312e-01,\n",
       "           1.4852e-01,  5.5664e-01],\n",
       "         [-2.5837e-01,  9.9431e-01, -1.9218e-02,  ..., -9.0534e-02,\n",
       "          -1.7739e-02,  5.4585e-01],\n",
       "         ...,\n",
       "         [ 2.6543e-02, -1.7981e-01,  4.8942e-01,  ..., -5.3213e-01,\n",
       "          -2.4651e-01,  4.6587e-01],\n",
       "         [-1.1945e-01, -2.3242e-01,  2.4277e-01,  ..., -4.7397e-01,\n",
       "          -1.3933e-01,  3.1804e-01],\n",
       "         [ 1.1076e-01, -7.5039e-02,  3.2258e-01,  ..., -7.3081e-02,\n",
       "          -5.1369e-01,  2.2897e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.0756,  0.0418, -0.2009,  ...,  0.1857, -0.0269,  0.0443],\n",
       "         [ 0.4123,  0.1266,  0.3189,  ...,  0.4447,  0.9412, -0.3549],\n",
       "         [-0.1503,  0.3128, -0.0155,  ..., -0.0342,  0.7499,  0.3273],\n",
       "         ...,\n",
       "         [-0.0991, -0.2563,  0.6976,  ...,  0.3403, -0.1549,  0.0583],\n",
       "         [-0.1885, -0.2625,  0.5826,  ...,  0.3815, -0.0672, -0.0038],\n",
       "         [-0.0658, -0.2083,  0.6080,  ...,  0.7090, -0.3491, -0.0987]],\n",
       "\n",
       "        [[ 0.1572,  0.0324, -0.1875,  ..., -0.1218,  0.1053,  0.1067],\n",
       "         [ 0.0656,  0.9108, -0.3554,  ...,  0.2502,  0.0229,  1.2729],\n",
       "         [-0.2750,  0.7314, -0.3511,  ...,  0.0339, -0.2085,  1.2596],\n",
       "         ...,\n",
       "         [-0.0222, -0.2214,  0.4551,  ...,  0.2376, -0.1432,  0.0923],\n",
       "         [-0.1027, -0.2282,  0.3156,  ...,  0.2350, -0.0780, -0.0043],\n",
       "         [ 0.0047, -0.1575,  0.3130,  ...,  0.5496, -0.3512, -0.0543]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.0329, -0.2109, -0.3710,  ...,  0.2740,  0.1218, -0.0202],\n",
       "         [ 0.5236,  0.1521,  0.9589,  ...,  0.9094,  0.7964, -1.0585],\n",
       "         [-0.2495,  0.3162, -0.1998,  ...,  0.1305,  0.3412,  0.0787],\n",
       "         ...,\n",
       "         [-0.2455, -0.4334,  0.6661,  ...,  0.9802, -0.3974, -0.0602],\n",
       "         [-0.3309, -0.2910,  0.6278,  ...,  1.0269, -0.3706, -0.1354],\n",
       "         [-0.0758, -0.2046,  0.5794,  ...,  1.4104, -0.6744, -0.0919]],\n",
       "\n",
       "        [[ 0.1548, -0.1363, -0.1660,  ..., -0.0123,  0.1191,  0.1368],\n",
       "         [ 0.5263,  0.8245,  0.0803,  ...,  0.1324, -0.2109,  0.9640],\n",
       "         [ 0.2179,  0.7779,  0.0129,  ..., -0.2032, -0.3873,  0.9725],\n",
       "         ...,\n",
       "         [-0.0995,  0.0555,  0.4285,  ...,  0.7738, -0.3910, -0.0346],\n",
       "         [-0.2225,  0.0193,  0.2552,  ...,  0.8570, -0.3070,  0.0087],\n",
       "         [-0.0862,  0.0902,  0.2375,  ...,  1.0074, -0.4554, -0.0699]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.0103, -0.3295, -0.1225,  ...,  0.2742,  0.1924,  0.1272],\n",
       "         [ 0.7675, -0.0515,  0.9827,  ...,  0.7896,  0.3260, -1.0598],\n",
       "         [-0.1832,  0.6007,  0.1599,  ..., -0.0386,  0.1447,  0.2190],\n",
       "         ...,\n",
       "         [-0.4755, -0.3750,  0.8642,  ...,  1.1494, -0.0680, -0.2065],\n",
       "         [-0.3059, -0.3059,  0.7778,  ...,  1.1964,  0.0411, -0.3059],\n",
       "         [-0.0440, -0.1893,  0.8244,  ...,  1.5072, -0.2421, -0.2403]],\n",
       "\n",
       "        [[ 0.1138, -0.2379,  0.0357,  ...,  0.2606,  0.1706,  0.3433],\n",
       "         [ 0.0753,  1.1680,  0.7051,  ...,  0.8139, -0.5748,  0.5526],\n",
       "         [-0.2307,  1.0202,  0.4029,  ...,  0.3278, -0.6737,  0.3179],\n",
       "         ...,\n",
       "         [-0.3682,  0.2737,  0.8583,  ...,  1.0231, -0.1546, -0.2243],\n",
       "         [-0.5874,  0.1441,  0.8220,  ...,  1.1450, -0.1143, -0.1575],\n",
       "         [-0.2751,  0.1702,  0.7790,  ...,  1.2223, -0.2391, -0.2437]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.1497, -0.6540, -0.6007,  ...,  0.3156,  0.1788,  0.4558],\n",
       "         [ 0.7525, -0.2583,  1.0645,  ...,  1.0973,  0.4042, -0.9366],\n",
       "         [-0.4223,  0.4690,  0.2899,  ...,  0.3627,  0.4119,  0.3409],\n",
       "         ...,\n",
       "         [-0.7055, -0.8518,  0.4630,  ...,  0.7921, -0.5112, -0.1022],\n",
       "         [-0.4719, -0.7912,  0.7661,  ...,  1.1931, -0.3861, -0.4019],\n",
       "         [-0.1797, -0.6948,  0.9212,  ...,  1.3915, -0.4592, -0.3357]],\n",
       "\n",
       "        [[ 0.3064, -0.2170, -0.4376,  ...,  0.5650, -0.2352,  1.0167],\n",
       "         [-0.0027,  1.1523,  0.4936,  ...,  0.6470, -0.6799,  0.6273],\n",
       "         [-0.5625,  0.8804, -0.0693,  ..., -0.0285, -1.1167,  0.4713],\n",
       "         ...,\n",
       "         [-0.4430, -0.1811,  0.9322,  ...,  1.1354, -0.1051, -0.2649],\n",
       "         [-0.8687, -0.4175,  0.7166,  ...,  1.1900, -0.2903, -0.0689],\n",
       "         [-0.4826, -0.3525,  0.9047,  ...,  1.3474, -0.3153, -0.1905]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.1487, -0.5972, -0.6492,  ..., -0.0943,  0.1758,  0.4735],\n",
       "         [ 0.6775, -0.3113,  0.5797,  ...,  0.8530,  0.6572, -0.9500],\n",
       "         [-0.1187,  0.1341, -0.2408,  ..., -0.0285,  0.5473,  0.4348],\n",
       "         ...,\n",
       "         [-0.4750, -0.3215,  0.5201,  ...,  0.2994, -0.1282, -0.1571],\n",
       "         [-0.2852, -0.2333,  1.0767,  ...,  0.7535, -0.3234, -0.7571],\n",
       "         [ 0.0505, -0.2509,  1.2524,  ...,  0.8574, -0.3822, -0.6127]],\n",
       "\n",
       "        [[ 0.2627, -0.1776, -0.4478,  ..., -0.2306, -0.2258,  0.8692],\n",
       "         [ 0.0044,  1.1460,  0.0536,  ...,  0.7541, -1.1454,  0.5818],\n",
       "         [-0.5131,  1.3198, -0.2807,  ..., -0.0888, -1.5143,  0.0973],\n",
       "         ...,\n",
       "         [-0.3406, -0.0927,  0.4498,  ...,  0.0701, -0.6562, -0.3503],\n",
       "         [-0.9402,  0.0331,  0.3898,  ...,  0.4080, -0.6101, -0.3539],\n",
       "         [-0.5040, -0.1694,  0.4720,  ...,  0.3972, -0.7127, -0.5079]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.1748, -0.8376, -0.4804,  ..., -0.0936,  0.6539,  0.2808],\n",
       "         [ 0.7901, -0.2782,  0.5766,  ...,  0.7492,  0.6049, -0.8344],\n",
       "         [-0.0983,  0.5900, -0.1780,  ..., -0.4555,  0.6773,  0.6428],\n",
       "         ...,\n",
       "         [-0.7929, -0.0756,  0.2702,  ..., -0.2310, -0.3045, -0.1721],\n",
       "         [-0.4867, -0.2466,  1.3321,  ...,  0.6847, -0.3892, -0.8616],\n",
       "         [-0.0862, -0.1392,  1.5945,  ...,  0.8888, -0.5315, -0.6702]],\n",
       "\n",
       "        [[ 0.2265, -0.3116, -0.6507,  ..., -0.0602, -0.2337,  0.9729],\n",
       "         [-0.4536,  1.1543,  0.4575,  ...,  0.4142, -0.6193,  0.3278],\n",
       "         [-0.6458,  1.6929, -0.1310,  ..., -0.4880, -1.2075, -0.0741],\n",
       "         ...,\n",
       "         [-0.3089,  0.1643,  0.7268,  ...,  0.2617, -0.5693, -0.4544],\n",
       "         [-1.1521,  0.1219,  0.4841,  ...,  0.1919, -0.6998, -0.2989],\n",
       "         [-0.5802, -0.0322,  0.7176,  ...,  0.3975, -0.6810, -0.5355]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.2529, -0.4999, -0.1519,  ..., -0.7340,  1.3038,  0.0627],\n",
       "         [ 0.4958, -0.2223,  0.1402,  ...,  0.8997,  0.7574, -0.8048],\n",
       "         [-0.4781,  0.7966, -0.1093,  ..., -0.4203,  1.2598,  0.5971],\n",
       "         ...,\n",
       "         [-0.5750, -0.6904, -0.7468,  ..., -0.5299,  0.3850,  0.1120],\n",
       "         [-0.2976, -0.5478,  1.3558,  ...,  0.7464,  0.1552, -1.0928],\n",
       "         [-0.0050, -0.3648,  1.6412,  ...,  0.9509, -0.2097, -0.7045]],\n",
       "\n",
       "        [[-0.0480,  0.0363, -0.8695,  ..., -0.3063,  0.0497,  1.1844],\n",
       "         [-0.0045,  1.2142,  0.3839,  ...,  0.5277, -0.3137,  0.1813],\n",
       "         [-0.1438,  1.3232, -0.5067,  ..., -0.0567, -0.6416,  0.1204],\n",
       "         ...,\n",
       "         [-0.0430,  0.3372,  0.8118,  ...,  0.2366, -0.4879, -0.3446],\n",
       "         [-0.9724,  0.1677,  0.3535,  ..., -0.0596, -0.4432, -0.1493],\n",
       "         [-0.3283,  0.0711,  0.8269,  ...,  0.2573, -0.4458, -0.4242]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.2262, -0.2007, -0.6170,  ..., -0.9245,  1.0133,  0.3220],\n",
       "         [ 0.5191, -0.0465,  0.3244,  ...,  0.4229,  0.8142, -0.6454],\n",
       "         [-0.7309,  0.6746, -0.0636,  ..., -0.6685,  0.6224,  0.6218],\n",
       "         ...,\n",
       "         [-0.9392, -0.6114, -0.8513,  ..., -0.7911, -0.0438,  0.0519],\n",
       "         [-0.5098, -0.4140,  1.3371,  ...,  0.5055, -0.0468, -1.4635],\n",
       "         [-0.0070, -0.2152,  1.7818,  ...,  1.0604, -0.6001, -0.9425]],\n",
       "\n",
       "        [[-0.1632,  0.3782, -1.1644,  ..., -1.0119, -0.0111,  1.2981],\n",
       "         [-0.0028,  1.2488,  0.4472,  ..., -0.0283, -0.0865,  0.0889],\n",
       "         [-0.6658,  1.1317, -0.4956,  ..., -0.6443, -0.7996,  0.2722],\n",
       "         ...,\n",
       "         [ 0.1179,  0.7454,  0.8057,  ...,  0.0236, -0.1617, -0.4978],\n",
       "         [-0.7786,  0.5325,  0.4822,  ..., -0.5544, -0.5836, -0.2115],\n",
       "         [-0.1018,  0.4582,  0.8814,  ..., -0.0677, -0.3106, -0.5295]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.0106,  0.0459, -0.6264,  ..., -0.3767,  0.5273,  0.2078],\n",
       "         [ 0.7064,  0.4278,  0.3257,  ...,  0.0108,  0.7318, -0.7642],\n",
       "         [-0.6601,  0.5206,  0.7655,  ..., -0.6401,  0.5373,  0.5419],\n",
       "         ...,\n",
       "         [-0.9143, -0.2741, -0.6237,  ..., -0.6551, -0.1603, -0.3350],\n",
       "         [-0.3345, -0.3570,  0.9674,  ...,  0.7295, -0.0018, -1.3490],\n",
       "         [-0.0917,  0.0759,  1.6441,  ...,  1.0124, -0.5038, -0.7775]],\n",
       "\n",
       "        [[-0.2785,  0.6145, -1.3515,  ..., -0.4649,  0.0018,  0.9693],\n",
       "         [-0.1558,  1.4046,  0.3491,  ...,  0.3304, -0.0376, -0.2410],\n",
       "         [-0.6465,  1.1286, -0.6993,  ..., -0.1774, -0.5509, -0.0690],\n",
       "         ...,\n",
       "         [ 0.1614,  0.9999,  0.8493,  ..., -0.1282, -0.3211, -0.6496],\n",
       "         [-0.5531,  0.6372,  0.1869,  ..., -0.5713, -0.6548, -0.4987],\n",
       "         [-0.0048,  0.7724,  0.9167,  ..., -0.0999, -0.4057, -0.6627]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.1361,  0.1025, -0.1871,  ..., -0.4196,  0.0885,  0.1530],\n",
       "         [ 0.7472,  0.3595,  0.7534,  ..., -0.4149,  0.5129, -0.8004],\n",
       "         [-0.9850,  0.7394,  1.3986,  ..., -1.0480,  0.3775,  0.2626],\n",
       "         ...,\n",
       "         [-1.1248, -0.2632, -0.0776,  ..., -0.2496, -0.1985, -0.3294],\n",
       "         [-0.8911, -0.3582,  1.1501,  ...,  0.7209, -0.0847, -1.0854],\n",
       "         [-0.3973,  0.2179,  1.5571,  ...,  0.5949, -0.4310, -0.5048]],\n",
       "\n",
       "        [[-0.4863,  0.6146, -1.1412,  ..., -0.2983, -0.6238,  0.6902],\n",
       "         [-0.1559,  1.1103,  0.6731,  ...,  0.3235,  0.1888, -0.2729],\n",
       "         [-0.4063,  0.5406,  0.1870,  ..., -0.3044, -0.3274, -0.2739],\n",
       "         ...,\n",
       "         [ 0.3377,  1.2714,  0.9377,  ..., -0.1996, -0.2516, -0.6044],\n",
       "         [-0.1669,  0.6751,  0.5964,  ..., -0.5162, -0.4953, -0.6175],\n",
       "         [ 0.2249,  1.0408,  0.9469,  ..., -0.3173, -0.2365, -0.6337]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[ 0.1746,  0.5190,  0.1795,  ..., -0.5524,  0.0540,  0.3766],\n",
       "         [ 1.0760,  0.7086,  0.5143,  ..., -0.6996,  0.3860, -0.7857],\n",
       "         [-0.7133,  0.8229,  1.0629,  ..., -1.0983,  0.9615,  0.3822],\n",
       "         ...,\n",
       "         [-0.6722,  0.0560,  0.2566,  ..., -0.0077, -0.1179, -0.6213],\n",
       "         [-0.7639, -0.1186,  1.3123,  ...,  0.6075,  0.1223, -1.0204],\n",
       "         [-0.2822,  0.4591,  1.7966,  ...,  0.1592, -0.3784, -0.1280]],\n",
       "\n",
       "        [[-0.3367,  0.7061, -0.2288,  ..., -0.5046, -0.3549,  0.4180],\n",
       "         [-0.2389,  1.0981,  0.4732,  ...,  0.1289,  0.4475,  0.2231],\n",
       "         [-0.3610,  0.7203,  0.2888,  ..., -0.2605, -0.1950, -0.0450],\n",
       "         ...,\n",
       "         [-0.1531,  1.2621,  1.0835,  ..., -1.0505,  0.0593,  0.1341],\n",
       "         [-0.4542,  0.9939,  1.0137,  ..., -1.3219, -0.1585,  0.1835],\n",
       "         [-0.2059,  1.1242,  1.1780,  ..., -1.2540,  0.0252,  0.1584]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), tensor([[[-0.1946,  0.4218,  0.0962,  ..., -0.3478,  0.2529,  0.6349],\n",
       "         [ 0.7205,  0.3380,  0.2394,  ..., -0.1110,  0.7642, -0.2834],\n",
       "         [-0.3903,  0.8112,  0.7443,  ..., -0.7822,  0.7367,  0.2825],\n",
       "         ...,\n",
       "         [-0.4875, -0.2214,  0.1221,  ...,  0.4432,  0.3382, -0.1994],\n",
       "         [-0.2706, -0.1727,  0.4868,  ...,  0.3528,  0.2161, -0.1844],\n",
       "         [-0.1614,  0.1447,  0.7015,  ...,  0.2477, -0.0427,  0.1529]],\n",
       "\n",
       "        [[-0.1275,  0.4207, -0.1118,  ..., -0.5984,  0.1164,  0.3813],\n",
       "         [ 0.1554,  0.8807,  0.5567,  ..., -0.1273,  0.6741,  0.4518],\n",
       "         [ 0.1242,  0.4439,  0.1214,  ...,  0.0824,  0.3178,  0.2108],\n",
       "         ...,\n",
       "         [-0.0509,  0.4513,  0.6253,  ..., -0.3548,  0.3023,  0.2539],\n",
       "         [-0.1632,  0.3350,  0.5181,  ..., -0.3476,  0.3227,  0.2318],\n",
       "         [-0.0741,  0.3763,  0.6270,  ..., -0.3889,  0.3013,  0.2214]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)), attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b982fe-fa53-4047-a2c5-83700b8251a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9250, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
