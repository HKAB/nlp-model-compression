{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca40d2b-9a54-4e04-9f6a-84bd6279bd95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PretrainedConfig,\n",
    "    SchedulerType,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "# My custom model\n",
    "from models import BertForSequenceClassification\n",
    "from models import DeeBertForSequenceClassification\n",
    "from models import BertConfig\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bbcb6-afa9-47cd-b521-12a65318cad0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test my BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5f4ceb-a543-432e-aa39-38652e90d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifiers.8.bias', 'classifiers.0.bias', 'exit_port.10.weight', 'classifiers.8.weight', 'classifiers.2.bias', 'exit_port.11.weight', 'exit_port.10.bias', 'exit_port.5.bias', 'exit_port.4.weight', 'classifiers.5.weight', 'classifiers.1.weight', 'classifiers.10.weight', 'exit_port.0.weight', 'classifiers.0.weight', 'exit_port.8.weight', 'classifiers.4.bias', 'exit_port.1.bias', 'exit_port.7.weight', 'classifiers.10.bias', 'classifiers.5.bias', 'classifiers.3.weight', 'classifiers.7.bias', 'exit_port.1.weight', 'classifiers.6.weight', 'classifiers.11.weight', 'exit_port.5.weight', 'classifiers.2.weight', 'exit_port.9.weight', 'exit_port.4.bias', 'exit_port.2.weight', 'classifiers.9.weight', 'exit_port.8.bias', 'exit_port.9.bias', 'classifiers.4.weight', 'exit_port.2.bias', 'classifiers.6.bias', 'exit_port.6.weight', 'classifiers.1.bias', 'exit_port.6.bias', 'classifiers.3.bias', 'classifiers.7.weight', 'exit_port.3.bias', 'exit_port.0.bias', 'exit_port.7.bias', 'classifiers.9.bias', 'exit_port.11.bias', 'classifiers.11.bias', 'exit_port.3.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# change model pretrained path here\n",
    "config = BertConfig(exit_port_threshold=0.1, entropy_threshold=0.2)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ce5303-9cc9-46dd-8b2e-07142aab3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0) # batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56c5c87-87e1-4272-9d26-4e9e12564a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first phrase\n",
    "outputs = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2196eb-252b-479d-a627-a2e0b8a00dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second phrase\n",
    "outputs = model.exit_forward(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595af8d4-44a3-47c6-8f73-a3fde6938ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6593, 1.0000],\n",
       "        [0.6593, 1.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.entropy_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae60a1d-0451-45bd-82e9-b3cc3e732daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2306971-b0fe-41ba-b1e4-c63bf05e5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world Yo yo\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed676c69-743b-4c07-887d-b2a59f946ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.exit_inference_forward(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca89e24-f9ed-4017-a138-ff680d36d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stop_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947ab01-c354-4424-b21b-f0db5deb3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb56250-2827-4aa4-b205-a3dca3cdbc5f",
   "metadata": {},
   "source": [
    "# Test DeeBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5e2de-256f-48f1-b975-7e49c8d6b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# change model pretrained path here\n",
    "config = BertConfig(entropy_threshold=0.5)\n",
    "model = DeeBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9333b48-cf37-450d-9219-effdd11ae875",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"Hello, my dog is cute and I am the biggest person in the world haha, Excuse me\"], \n",
    "                   max_length = 128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "labels = torch.tensor([0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedee9bf-73db-4db3-940d-17d25dd6f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first phrase\n",
    "outputs = model(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe2e60-8452-4ec9-808d-6d54b5333199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second phrase\n",
    "outputs = model.exit_inference_forward(**inputs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeed24f-a8fd-4bb0-9a58-30733cb07c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stop_layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
